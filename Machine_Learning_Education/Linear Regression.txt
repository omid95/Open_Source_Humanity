Linear Regression.
Consider 10 judges at a talent show, suppose 6 of the judges are professional and usually provide the same score for some of the participants in the show and at times these can be different but close. The other 4 judges are juniors and try to follow what the seniors decide.
One of the ways to model this behaviour is by using the mean. The Mean tries to find the score that they will all give by summing the value each judge gave to a candidate. If the 6 judges give a seven to a particular candidate, the method of using mean suggests getting the sum of the scores and dividing it by the number of judges. 7+7+7+7+7+7 divided by 6. The answer from this is 7 and the remaining 4 judges are expected to also give a 7. But this is not the case since the 6 judges cannot provide the same score and it's not guaranteed that the 4 judges would follow this for other candidates since they may also have their own opinions.


The other method we can use is variance. What this does is try to find out how big of a deviation each judge scored a particular candidate and this can be a better measure than the mean since it deals with the fact that the 6 judges either give the same score or similar scores. The variance can be calculated by, (sum (x- mean(x))^2)/ n -1 where n is the number of judges. This is a good metric but doesn't put into account the fact that these scores from each judge can vary from the mean depending on the participant and thus this only deals with one participant. To be able to factor in other participants we use the covariance. What covariance does is, it tries to measure how much the scores from the different judges vary from the mean and how much the skillsets of each participant vary from the mean. The participants measure their scores from how many skillsets they have and the maximum can be 7. The covariance can be measured from (sum((x-mean(x))(y-mean(y)))/n-1. This is a better metric since it factors in the factors that also score the different participants and thus does not only use scores from the judges.


An accurate metric to use is one which tries to deal with each of the judges alone and the different skill sets of participants. Let x be the skillsets that a participant has, and y be the scores from the judges. To get a metric that considers a specific judge, we divide the covariance by the variance and this metric provides a change in y for a unit change in x meaning if we get a skillset x and multiply it with this acquired number, we can get the prediction that is expected from the judges. The equation representing this relationship is y = mx where m is the value calculated from the division of covariance by variance and it can also be the slope. This method is also not the most accurate and thus a bias term is introduced to cater for the fact that different judges may have different opinions on different participants. The bais term, b0 is calculated from; b0 = y - mx showing the deviation of what is predicted from the real. 


This slope can be calculated in different ways and the method presented in this document is one of the methods. The other method is an approach where covariance and variance are not used to calculate this but an algorithm is set up to provide different values of the slope b1, and bias b0. As this is done, the deviation of the predicted value from the real value is calculated and this is known as the loss. The goal of the learning algorithm is to minimise this value as it provides different b1 and b0 values. It minimises this loss by using the gradient descent method which will soon be covered.